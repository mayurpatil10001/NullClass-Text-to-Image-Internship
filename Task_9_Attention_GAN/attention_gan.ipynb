{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 9: Attention GAN\n",
        "\n",
        "This notebook implements a GAN with self-attention mechanism for improved image generation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Self-Attention Module\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, in_dim):\n",
        "        super(SelfAttention, self).__init__()\n",
        "        self.query = nn.Linear(in_dim, in_dim)\n",
        "        self.key = nn.Linear(in_dim, in_dim)\n",
        "        self.value = nn.Linear(in_dim, in_dim)\n",
        "        self.gamma = nn.Parameter(torch.zeros(1))\n",
        "    \n",
        "    def forward(self, x):\n",
        "        batch_size, channels, height, width = x.size()\n",
        "        x_flat = x.view(batch_size, channels, height * width).permute(0, 2, 1)\n",
        "        \n",
        "        q = self.query(x_flat)\n",
        "        k = self.key(x_flat)\n",
        "        v = self.value(x_flat)\n",
        "        \n",
        "        attn = torch.softmax(q @ k.transpose(-2, -1), dim=-1)\n",
        "        out = (attn @ v).permute(0, 2, 1).view(batch_size, channels, height, width)\n",
        "        \n",
        "        return self.gamma * out + x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generator with Attention\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.fc1 = nn.Linear(102, 128)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.attention = SelfAttention(128)\n",
        "        self.fc2 = nn.Linear(128, 28*28)\n",
        "        self.tanh = nn.Tanh()\n",
        "    \n",
        "    def forward(self, z, labels):\n",
        "        x = torch.cat((z, labels), dim=1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        # Reshape for attention (simplified - in practice would need proper reshaping)\n",
        "        x = x.unsqueeze(-1).unsqueeze(-1)  # Add spatial dimensions\n",
        "        x = self.attention(x)\n",
        "        x = x.squeeze(-1).squeeze(-1)  # Remove spatial dimensions\n",
        "        x = self.fc2(x)\n",
        "        return self.tanh(x).view(-1, 28, 28)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Discriminator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(28*28+2, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    \n",
        "    def forward(self, img, labels):\n",
        "        x = torch.cat((img.view(-1, 28*28), labels), dim=1)\n",
        "        return self.model(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize and Train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "generator = Generator()\n",
        "discriminator = Discriminator()\n",
        "criterion = nn.BCELoss()\n",
        "g_optimizer = torch.optim.Adam(generator.parameters(), lr=0.001)\n",
        "d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.001)\n",
        "\n",
        "labels_dict = {\n",
        "    'square': torch.tensor([1, 0], dtype=torch.float32), \n",
        "    'circle': torch.tensor([0, 1], dtype=torch.float32)\n",
        "}\n",
        "\n",
        "print(\"Attention GAN models initialized!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training loop\n",
        "num_epochs = 100\n",
        "g_losses = []\n",
        "d_losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for label_name, label_tensor in labels_dict.items():\n",
        "        label_tensor = label_tensor.unsqueeze(0)\n",
        "        z = torch.randn(1, 100)\n",
        "        \n",
        "        # Train Discriminator\n",
        "        d_optimizer.zero_grad()\n",
        "        fake_img = generator(z, label_tensor)\n",
        "        d_fake = discriminator(fake_img.detach(), label_tensor)\n",
        "        d_loss = criterion(d_fake, torch.zeros(1))\n",
        "        d_loss.backward()\n",
        "        d_optimizer.step()\n",
        "        \n",
        "        # Train Generator\n",
        "        g_optimizer.zero_grad()\n",
        "        g_fake = discriminator(fake_img, label_tensor)\n",
        "        g_loss = criterion(g_fake, torch.ones(1))\n",
        "        g_loss.backward()\n",
        "        g_optimizer.step()\n",
        "        \n",
        "        g_losses.append(g_loss.item())\n",
        "        d_losses.append(d_loss.item())\n",
        "    \n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}] - G_Loss: {g_loss.item():.4f}, D_Loss: {d_loss.item():.4f}\")\n",
        "\n",
        "print(\"Training completed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize losses\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(g_losses, label='Generator Loss')\n",
        "plt.plot(d_losses, label='Discriminator Loss')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Losses - Attention GAN')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Generate samples\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
        "for idx, (label_name, label_tensor) in enumerate(labels_dict.items()):\n",
        "    z = torch.randn(1, 100)\n",
        "    label_tensor = label_tensor.unsqueeze(0)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        generated_img = generator(z, label_tensor).detach().numpy()\n",
        "    \n",
        "    axes[idx].imshow(generated_img[0], cmap='gray')\n",
        "    axes[idx].set_title(f\"Generated {label_name.capitalize()} with Attention\")\n",
        "    axes[idx].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
