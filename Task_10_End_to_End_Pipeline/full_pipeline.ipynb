{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 10: End-to-End Text-to-Image Pipeline\n",
        "\n",
        "This notebook implements a complete end-to-end pipeline for text-to-image generation, including text preprocessing, embedding, and image generation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import BertTokenizer\n",
        "import re\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Text Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    \"\"\"Clean and preprocess text input\"\"\"\n",
        "    cleaned = text.lower()\n",
        "    cleaned = re.sub(r'[^a-zA-Z0-9\\s]', '', cleaned)\n",
        "    return cleaned\n",
        "\n",
        "# Example\n",
        "text = \"Generate an image of a beautiful sunset!!!\"\n",
        "cleaned_text = preprocess_text(text)\n",
        "print(f\"Original: {text}\")\n",
        "print(f\"Cleaned: {cleaned_text}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Text Embedding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "def get_text_embedding(text):\n",
        "    \"\"\"Convert text to embedding\"\"\"\n",
        "    cleaned = preprocess_text(text)\n",
        "    encoded = tokenizer(cleaned, return_tensors='pt', padding='max_length', truncation=True, max_length=77)\n",
        "    return encoded['input_ids'].float()\n",
        "\n",
        "# Example\n",
        "text_emb = get_text_embedding(text)\n",
        "print(f\"Text embedding shape: {text_emb.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generator Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(77+100, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 28*28),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "    \n",
        "    def forward(self, z, text_emb):\n",
        "        x = torch.cat((z, text_emb), dim=1)\n",
        "        return self.model(x).view(-1, 28, 28)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(28*28+77, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    \n",
        "    def forward(self, img, text_emb):\n",
        "        x = torch.cat((img.view(-1, 28*28), text_emb), dim=1)\n",
        "        return self.model(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Complete Pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "generator = Generator()\n",
        "discriminator = Discriminator()\n",
        "criterion = nn.BCELoss()\n",
        "g_optimizer = torch.optim.Adam(generator.parameters(), lr=0.001)\n",
        "d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.001)\n",
        "\n",
        "print(\"Models initialized!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_image_from_text(text, num_iterations=100):\n",
        "    \"\"\"Complete pipeline: text -> embedding -> image\"\"\"\n",
        "    # Preprocess and embed text\n",
        "    text_emb = get_text_embedding(text)\n",
        "    \n",
        "    # Generate random noise\n",
        "    z = torch.randn(1, 100)\n",
        "    \n",
        "    # Training iterations\n",
        "    for _ in range(num_iterations):\n",
        "        fake_img = generator(z, text_emb)\n",
        "        \n",
        "        # Train Discriminator\n",
        "        d_optimizer.zero_grad()\n",
        "        d_fake = discriminator(fake_img.detach(), text_emb)\n",
        "        d_loss = criterion(d_fake, torch.zeros(1))\n",
        "        d_loss.backward()\n",
        "        d_optimizer.step()\n",
        "        \n",
        "        # Train Generator\n",
        "        g_optimizer.zero_grad()\n",
        "        g_fake = discriminator(fake_img, text_emb)\n",
        "        g_loss = criterion(g_fake, torch.ones(1))\n",
        "        g_loss.backward()\n",
        "        g_optimizer.step()\n",
        "    \n",
        "    # Generate final image\n",
        "    with torch.no_grad():\n",
        "        generated_img = generator(z, text_emb).detach().numpy()\n",
        "    \n",
        "    return generated_img[0]\n",
        "\n",
        "# Example usage\n",
        "text_prompts = [\n",
        "    \"A beautiful sunset over mountains\",\n",
        "    \"A red car on a highway\",\n",
        "    \"A cat sitting on a windowsill\"\n",
        "]\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "for idx, prompt in enumerate(text_prompts):\n",
        "    img = generate_image_from_text(prompt, num_iterations=50)\n",
        "    axes[idx].imshow(img, cmap='gray')\n",
        "    axes[idx].set_title(f\"Generated for:\\n{prompt[:30]}...\")\n",
        "    axes[idx].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"End-to-end pipeline completed!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
