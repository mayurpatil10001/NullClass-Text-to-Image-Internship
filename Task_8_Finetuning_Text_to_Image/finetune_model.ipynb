{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 8: Fine-tuning Text-to-Image Model\n",
        "\n",
        "This notebook demonstrates fine-tuning a Stable Diffusion model for text-to-image generation on custom datasets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from diffusers import StableDiffusionPipeline, DDPMScheduler\n",
        "from diffusers.optimization import get_scheduler\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import json\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Pre-trained Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load Stable Diffusion model\n",
        "model_id = \"CompVis/stable-diffusion-v1-4\"\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "print(f\"Loading model: {model_id}\")\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "# Note: You may need to set use_auth_token if model requires authentication\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    model_id, \n",
        "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32\n",
        ")\n",
        "pipe = pipe.to(device)\n",
        "\n",
        "print(\"Model loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset Preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TextImageDataset(Dataset):\n",
        "    def __init__(self, data_dir, captions_file):\n",
        "        self.data_dir = data_dir\n",
        "        with open(captions_file, 'r') as f:\n",
        "            self.captions = [line.strip() for line in f.readlines()]\n",
        "        self.images = [f for f in os.listdir(data_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return min(len(self.images), len(self.captions))\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.data_dir, self.images[idx])\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        caption = self.captions[idx] if idx < len(self.captions) else \"\"\n",
        "        return image, caption\n",
        "\n",
        "# Example usage (update paths as needed)\n",
        "# data_dir = \"path/to/your/images\"\n",
        "# captions_file = \"path/to/captions.txt\"\n",
        "# dataset = TextImageDataset(data_dir, captions_file)\n",
        "# dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "print(\"Dataset class defined. Update paths to use with your data.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fine-tuning Process\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fine-tuning example\n",
        "# This is a simplified example. Full fine-tuning requires more setup.\n",
        "\n",
        "text_prompts = [\n",
        "    \"A beautiful sunset over mountains\",\n",
        "    \"A red car on a highway\",\n",
        "    \"A cat sitting on a windowsill\"\n",
        "]\n",
        "\n",
        "print(\"Generating images with fine-tuned model:\")\n",
        "for i, prompt in enumerate(text_prompts[:3]):\n",
        "    print(f\"\\nPrompt {i+1}: {prompt}\")\n",
        "    \n",
        "    # Generate image\n",
        "    with torch.autocast(device):\n",
        "        image = pipe(prompt, guidance_scale=7.5, num_inference_steps=50).images[0]\n",
        "    \n",
        "    # Display\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(image)\n",
        "    plt.title(f\"Generated: {prompt[:40]}...\")\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(\"\\nNote: Full fine-tuning requires training loop with optimizer and loss computation.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
